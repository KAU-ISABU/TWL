# 확률론 기초

<br>

- Machine Learning은 데이터를 기반으로 발전한 분야이지만, 그 뿌리가 되는 학문/분야는 **통계학** 이라고 볼 수 있습니다.
- 데이터를 다루는 통계학 또한 **확률론**의 개념들을 이용해 문제를 해결하고, 모형을 설명합니다.
  - 어떻게 보면 확률론의 내용을 통해 통계 기법이 이뤄진다 로 봐도 될 것 같습니다.
- 이번 정리본에선 ML에 들어가기에 앞서 알아두면 좋을 기초적인 확률론의 내용을 적어보고자 합니다. 

<br>
<br>

## 1. Probability Theory - Introduction

<br>

- **자연계의 수 많은 불확실성을 다루기 위한 수학의 한 분야**로 시스템의 신뢰성, 측정값의 정확도 분석과 같은 문제들을 해결하고자 하는데 주로 활용되는 학문입니다.
    - 확률(Probability, 사건의 빈도)을 분석/연구하는 분야로 볼 수 있습니다.
- 한 실험에서 모든 가능한 결과를 모은 공간을 **표본 공간(Sample Space)** 이라 하며, 이 실험에서 특정 실험 결과가 나올 가능성을 **확률 (Probability)** 이라고 합니다.
- 실험에서 특정 결과들의 집합을 **사건(Event)** 이라고 합니다.
  - 이 특정 결과들의 집합이 아닌 부분을 **여사건(Complementary Event)** 이라고 합니다.   
> 대표적인 동전 2개를 던지는 실험을 생각해봅시다.   
> 앞면을 $H$, 뒷면을 $T$ 라고 하면 이 실험에 대한 표본공간 $S$는 다음과 같이 표현할 수 있습니다.   
> <center>
> 
> $S=\{(H, T), (H, H), (T, H), (T, T)\}$   
> </center>
> 
> 이때 $(H, T)$와 $(T, H)$는 서로 다른 사건입니다.  
> 
> 동전 2개가 같은 면을 나타내는 사건을 $A$라고 한다면, $A=\{(H,H), (T,T)\}$가 될 것이고   
> 동전 2개가 다른 면을 나타내는 사건, 즉 $A$의 여사건은 $A^c=\{(H,T), (T,H)\}$가 됩니다.



- **확률**을 약간 수학적으로 정의하면 다음처럼 정의할 수 있습니다.

<br>
<center>

표본공간 $S=\{O_1, O_2, ..., O_n\}$ 으로 구성된 실험에 대한 확률값 집합은
<br>
각각의 요소에 대한 확률값 $P_1, P_2, ..., P_n$을 갖고, $0\le P_1 \le1, 0\le P_2 \le1, ... 0\le P_n \le1$ 이며, $P_1 + P_2 + ... + P_n = 1$ 이다.
<br>
특정 사건 $O_i$가 발생할 확률을 $p_i$라 할때, 기호로 $P(O_i) = p_i$와 같이 표기한다.

</center>
<br>

- **사건**을 약간 수학적으로 정의하면 다음처럼 정의할 수 있습니다.

<br>
<center>

사건 $A$는 표본공간 $S$의 부분집합(subset)으로, 특정 관심 대상인 결과들의 집합이다.   
$P(A)$는 사건 $A$에 속하는 결과들의 확률의 총 합으로 구할 수 있다.  
또한, 사건 $A$에 속하지 않는 표본공간 내의 다른 모든 결과의 집합을 여사건 이라 하며,   
$P(A) + P(A^c) = P(S) = 1$ 의 관계가 성립한다.

</center>
<br>